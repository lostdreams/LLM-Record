
# Prompt 

prompt的设计，两个方面，一个是激发LLM能力，一个是越狱和攻击，还有一个是In-context-learning

-  On Prompt-Driven Safeguarding for Large Language Models ： 探究Prompt对于LLM安全使用的问题
-  FlipAttack: Jailbreak LLMs via Flipping ： Prompt越狱
-   [Trained Transformers Learn Linear Models In-Context](https://www.zhihu.com/question/596595451/answer/3080514847) :  ICL的内部机制的分析
-  [In-context Learning and Induction Heads](https://zhuanlan.zhihu.com/p/671697479) :     [Anthropic](https://transformer-circuits.pub/2022/in-context-learning-and-induction-heads/index.html#argument-architectural-requirements)写的文章
- [自动化prompt生成(AuTo Prompt)](https://zhuanlan.zhihu.com/p/819165874)
- https://github.com/jxzhangjhu/Awesome-LLM-Prompt-Optimization

- **使用Prompt做UML图生成，即转化为PlantUML语言或MERMAID语言**

- [self-refine](https://zhuanlan.zhihu.com/p/721788160)


 - ** 如何对Prompt中的某些词进行重点关注，**：
	 - 类似于SD模型中的某些词的权重添加
     - prompt的表达是否有更好的优化方式，即对于大模型来说有更好的理解，找到大模型中的prompt的重要因子！
     - 


# 模型蒸馏

按照压缩即智能的理论，如果模型只是在记忆答案而不是真的理解推理过程，说明压缩的还不够，按照阿卡姆剃刀原则，记忆答案显然不是模型的最优表达。如果一道题目只是换了个数字，转换一下形式，模型就回答不出来了，显然模型并没有真的理解背后的数学模型。

所以应当在模型基础上继续蒸馏，使用较小的模型蒸馏较大的模型，如果在这个过程中模型loss难以降低，说明两种情况：1. 原来的教师模型已经是最优解 2. 学生模型的表达能力不足，以至于没办法学习到更深层的表达能力。

蒸馏的方法，应当是降低模型参数和降低模型的向量空间维数。不知道有没有消融实验来验证这一点。



模型蒸馏的两个方面： 1. embedding的维度蒸馏  2. 模型的参数蒸馏  。  先进行模型的参数蒸馏，此时底层的维度应当和高层的维度一样，全部保留教师模型的embedding值，然后只更新学生模型的参数  然后进行embedding维度的蒸馏，此时保留学生模型的参数，但是不行，embedding维度限制死了模型的输入，


低纬的向量空间和高维的向量空间，同样的分布有什么表达上的差别么。

# character AI



# 因果学习 拒绝学习

自我拒绝 ： https://zhuanlan.zhihu.com/p/2758790985
因果推断： 



# 统计+符号



# 反演 插值


插值在图像编辑领域是一个不错的想法，同时在NLP里面 soft prompt方法也可以理解为是一种插值，即 在最完美的prompt和 hard prompt之间取一个中间值。不知道怎么做这件事。



# For video 


Training-free Video LLM方向，只需要一张GPU就可以做[link](https://www.zhihu.com/question/629933996)

听起来有点像是当初的DIffusion 编辑的领域






# 机器学习 For AI



# PDF Parser


- chatDoc
- 

# 参考

- 实验室一块GPU都没有怎么做深度学习？
- 有没有人可以一个人在家发表 AI 顶会论文？
