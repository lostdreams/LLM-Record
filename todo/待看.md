# 2025年9月30日

https://zhuanlan.zhihu.com/p/15567883765 | LLM之Rag学习：再探KnowledgeGraph实现细节 - 知乎
https://www.zhihu.com/column/c_1662098877871296512 | LLM(大语言模型)学习 - 知乎
https://zhuanlan.zhihu.com/p/674019932 | 万字长文+详细公式推导解读扩散模型的经典论文 - 知乎
https://zhuanlan.zhihu.com/p/675509396 | 一文读懂：大模型RAG（检索增强生成）含高级方法 - 知乎
https://zhuanlan.zhihu.com/p/23819511816 | RAG科普文！检索增强生成的技术全景解析 - 知乎
https://zhuanlan.zhihu.com/p/20585825634 | Deepseek的RL算法GRPO解读 - 知乎
https://zhuanlan.zhihu.com/p/537552626 | CC-Riddle：汉字谜语问答数据集 - 知乎
https://zhuanlan.zhihu.com/p/31458886937 | 碎碎念：关于 Manus 的细枝末节 - 知乎
https://zhuanlan.zhihu.com/p/32418511814 | 论文解读GraphRAG - 知乎
https://zhuanlan.zhihu.com/p/2425550178 | 深入理解Agent：从0实现function call - 知乎
https://jx.huawei.com/TI/report/details/69d80bf69e68459684fec55bd794a39f?shareType=authorPush&comefrom=espace&welink_open_uri=aDU6Ly80NzE2NTE3MzE0Nzc5NTcvaHRtbC9pbmRleC5odG1sIy9qeC9kZXRhaWw%2FaWQ9NjlkODBiZjY5ZTY4NDU5Njg0ZmVjNTViZDc5NGEzOWYmdHlwZT10ZWNobmljYWxTZXJ2aWNlLXJlcG9ydCZjb21lZnJvbT1lc3BhY2U%3D | jx.huawei.com/TI/report/details/69d80bf69e68459684fec55bd794a39f?shareType=authorPush&comefrom=espace&welink_open_uri=aDU6Ly80NzE2NTE3MzE0Nzc5NTcvaHRtbC9pbmRleC5odG1sIy9qeC9kZXRhaWw%2FaWQ9NjlkODBiZjY5ZTY4NDU5Njg0ZmVjNTViZDc5NGEzOWYmdHlwZT10ZWNobmljYWxTZXJ2aWNlLXJlcG9ydCZjb21lZnJvbT1lc3BhY2U%3D
https://www.zhihu.com/question/11667247329/answer/120297805134 | 推理大模型与普通大模型的区别是什么？ - 知乎
https://zhuanlan.zhihu.com/p/1891578572298240079 | python asyncio 的常见错误 - 知乎
https://zhuanlan.zhihu.com/p/1892875680863191525 | 基于LlamaIndex实现CodeAct Agent：代码执行工作流的技术架构与原理 - 知乎
https://zhuanlan.zhihu.com/p/1894127887931662445 | 朴素贝叶斯法与csgo队友是否是坑货 - 知乎
https://www.zhihu.com/question/659305847/answer/119512863129 | 学习检索增强生成 RAG时，多数人是不是从Llamaindex学起，首先研究和改写哪个RAG开源代码？ - 知乎
https://zhuanlan.zhihu.com/p/687851153 | RAG性能优化终极指南 - 知乎
https://juejin.cn/post/7333047669742960690 | 【LLM】如何基于 Claude 写好一个针对超长文档的 prompt本文介绍了一套详细的指南和技巧，旨在帮助用户最大化 - 掘金
https://jx.huawei.com/community/comgroup/postsDetails?postId=8abe105c09b645818bf4d645e6ce58db&noTop=true&type=freePost&previou=comments&shareType=authorPush&comefrom=espace&welink_open_uri=aDU6Ly80NzE2NTE3MzE0Nzc5NTcvaHRtbC9pbmRleC5odG1sIy9qeC9kZXRhaWw%2FaWQ9OGFiZTEwNWMwOWI2NDU4MThiZjRkNjQ1ZTZjZTU4ZGImdHlwZT1wb3N0JmNvbWVmcm9tPWVzcGFjZQ%3D%3D | 稼先社区
https://zhuanlan.zhihu.com/p/1904863611836404922 | AM-Thinking-v1：在32B规模上推动推理能力的边界 - 知乎
https://www.zhihu.com/question/639863879/answer/1910016269656257623 | 抱歉，该内容已被作者删除 - 知乎
https://zhuanlan.zhihu.com/p/1909636778828207960 | 使用Qwen3开发智能体：结构化输出与思考模式切换 - 知乎
https://zhuanlan.zhihu.com/p/13851303366 | 深入浅出LlamaIndex Workflows: 事件驱动的LLM架构 - 知乎
https://www.zhihu.com/question/7468595725 | 如何利用cursor快速理解复杂代码工程？ - 知乎
https://zhuanlan.zhihu.com/p/1910708398573482392 | 蒙特卡洛树搜索五篇：Residual-EBM、AlphaMath、MCTS-DPO、DPO as Q、AlphaLLM - 知乎
https://zhuanlan.zhihu.com/p/24214732238 | 自回归是否是通往语言智能的唯一路径？——生成模型的一些思考（3） - 知乎
https://login.huawei.com/login1/?redirect=https%3A%2F%2F3ms.huawei.com%2Fkm%2Fgroups%2F3950546%2Fblogs%2Fdetails%2F20542430%3Fl%3Dzh-cn%26moduleId%3D724781573303463936 | login.huawei.com/login1/?redirect=https%3A%2F%2F3ms.huawei.com%2Fkm%2Fgroups%2F3950546%2Fblogs%2Fdetails%2F20542430%3Fl%3Dzh-cn%26moduleId%3D724781573303463936
https://zhuanlan.zhihu.com/p/1912830613263722347 | Cursor 后台Agent：这个AI助手能24小时帮你干活 🚀 - 知乎
https://kexue.fm/archives/9009 | 为什么Pre Norm的效果不如Post Norm？ - 科学空间|Scientific Spaces
https://www.zhihu.com/question/1907422978985169131 | 如何看待Qwen推出的新Scaling Law ——Parallel Scaling？ - 知乎
https://zhuanlan.zhihu.com/p/1914275198242359148 | 自由能原理和世界模型 - 知乎
https://www.zhihu.com/question/1914113051533214795/answer/1915204634584260663 | 如何评价google于6月5日发布的gemini2.5pro 0605版本？和之前的版本有什么不同？ - 知乎
https://zhuanlan.zhihu.com/p/663770472 | 大模型工具调用(function call)原理及实现 - 知乎
https://www.zhihu.com/people/hzwer/posts | hzwer 黄哲威 - 知乎
https://www.zhihu.com/people/la-la-la-54-59-32/posts | 大模型最新论文 - 知乎
https://zhuanlan.zhihu.com/p/1916114024749336273 | 万字长文--全网独家首次解密cursor核心原理：如何手把手打造AI Native IDE - 知乎
https://zhuanlan.zhihu.com/p/27513633121 | 最大可验证代码合成数据的背后：合成数据的危与机 - 知乎
https://zhuanlan.zhihu.com/p/645715484 | 手把手教你训练千亿级LLM模型（一）：准备工作 - 知乎
https://www.zhihu.com/question/1914286810902827620/answer/1916628938874155857 | 阿里开源 Qwen3 新模型 Embedding，该模型的框架设计有哪些优势？ - 知乎
https://zhuanlan.zhihu.com/p/1916865679484747890 | 为什么不建议构建多智能体？《Don’t Build Multi-Agents》 博客解读 - 知乎
https://login.huawei.com/login1/?redirect=https%3A%2F%2F2012labs.huawei.com%2F%23%2Fdiscussion%2F1149502971294191616%2Fdetail | login.huawei.com/login1/?redirect=https%3A%2F%2F2012labs.huawei.com%2F%23%2Fdiscussion%2F1149502971294191616%2Fdetail
https://zhuanlan.zhihu.com/p/1917713171399025766 | 针锋相对？Anthropic分享多智能研究系统设计实践 - 知乎
https://zhuanlan.zhihu.com/p/699146624 | [LLM-Agents]详解Agent中规划工作流Workflow - 知乎
https://zhuanlan.zhihu.com/p/1913883084497097585 | 当蒙特卡洛树搜索算法遇上LLM - 知乎
https://www.zhihu.com/question/592626839/answer/1917910859499443288 | 为什么Self-Attention要通过线性变换计算Q K V，背后的原理或直观解释是什么？ - 知乎
https://www.zhihu.com/question/1918348812491141733/answer/1918580718688244105 | MiniMax 推出全球首个开源大规模混合架构的推理模型 MiniMax-M1，其有何技术优势？ - 知乎
https://www.google.com/search?q=in-context+reinforcement+learning&newwindow=1&sca_esv=0619bf7b847f9363&sxsrf=AE3TifNrUSjekjQtSG81C_rJRa2TusbRXQ%3A1750297083862&ei=-2lTaImyNPXBjuMP3LWewA8&ved=0ahUKEwjJm73frPyNAxX1oGMGHdyaB_gQ4dUDCBA&uact=5&oq=in-context+reinforcement+learning&gs_lp=Egxnd3Mtd2l6LXNlcnAiIWluLWNvbnRleHQgcmVpbmZvcmNlbWVudCBsZWFybmluZzIFEAAYgAQyCBAAGIAEGMsBMgUQABiABDIFEAAYgAQyBRAAGIAEMgUQABiABDIEEAAYHjIEEAAYHjIEEAAYHjIEEAAYHkjNB1DsA1jsA3ADeAGQAQCYAWqgAWqqAQMwLjG4AQPIAQD4AQL4AQGYAgSgAnrCAgoQABiwAxjWBBhHmAMAiAYBkAYKkgcDMy4xoAfVBrIHAzAuMbgHbsIHBTAuMi4yyAcN&sclient=gws-wiz-serp | in-context reinforcement learning - Google Search
https://www.zhihu.com/people/xu-liang-57-86/posts | 诚毅 - 知乎
https://github.com/anthropics/claude-cookbooks/blob/main/patterns/agents/basic_workflows.ipynb | claude-cookbooks/patterns/agents/basic_workflows.ipynb at main · anthropics/claude-cookbooks
https://zhuanlan.zhihu.com/p/1919029686526255253 | 高知识密度推理需要怎么训练？KNOWLEDGE or REASONING ? A Close Look at How LLMs Think Across Domains - 知乎
https://www.cnblogs.com/theseventhson/p/18315598 | LLM大模型：推理优化-vLLM显存使用优化 - 第七子007 - 博客园
https://zhuanlan.zhihu.com/p/1919438311358961114 | 《Enterprise RAG Challenge比赛》的一些摘录笔记 - 知乎
https://zhuanlan.zhihu.com/p/1920046205553074488 | Agent编码工具 Claude Code 相关资源汇总 - 知乎
https://www.zhihu.com/question/1919712376204256921 | 月之暗面 Kimi 首个 Agent 开启内测，可生成易追溯的万字报告，有哪些技术亮点？ - 知乎
https://zhuanlan.zhihu.com/p/1920267860699247892 | 【源码拾贝】docext的使用 - 知乎
https://zhuanlan.zhihu.com/p/1920858622344279299 | 合成数据>人工数据，绝对性能暴涨超10个点！仅需任务定义，高效微调大模型 - 知乎
https://zhuanlan.zhihu.com/p/1919889301719737482 | 🚀Cursor+Serena最佳组合告别AI编程工具短板！支持Claude Code、windsurf、Cline！让AI编程不再是简单读取代码而是智能分析依赖关系，让复杂开源项目二次开发效率提升十倍 - 知乎
https://zhuanlan.zhihu.com/p/30039353831 | 基于OpenAI Agent SDK的多智能体小说创作框架实践——novel-multi-agents - 知乎
https://zhuanlan.zhihu.com/p/1920067237676578781 | 首个全面评估图检索增强生成的基准测试GraphRAG-Bench - 知乎
https://zhuanlan.zhihu.com/p/721073733 | 人人都能看懂的DPO数学原理 - 知乎
https://www.zhihu.com/question/1911182336298586477/answer/1921187969496223974 | 如何解决Cursor等Agent编码开发轮次多了过后代码库变成屎山的问题？ - 知乎
https://zhuanlan.zhihu.com/p/1921560450421720084 | Grokking现象为何不能泛化知识推理的第二跳？——How does Transformer Learn Implicit Reasoning?论文阅读笔记【1】 - 知乎
https://zhuanlan.zhihu.com/p/1900302391011685181 | Gemini Embedding在多语言、代码理解、分类、检索、聚类等任务上的卓越性能 - 知乎
https://login.huawei.com/login1/?redirect=https%3A%2F%2F3ms.huawei.com%2Fnext%2Fgroups%2Findex.html%23%2Fwiki%2Fdetail%3FgroupId%3D2027987%26wikiId%3D7569273 | login.huawei.com/login1/?redirect=https%3A%2F%2F3ms.huawei.com%2Fnext%2Fgroups%2Findex.html%23%2Fwiki%2Fdetail%3FgroupId%3D2027987%26wikiId%3D7569273
https://login.huawei.com/login1/?redirect=https%3A%2F%2F3ms.huawei.com%2Fkm%2Fblogs%2Fdetails%2F15480792 | login.huawei.com/login1/?redirect=https%3A%2F%2F3ms.huawei.com%2Fkm%2Fblogs%2Fdetails%2F15480792
https://login.huawei.com/login1/?redirect=https%3A%2F%2F3ms.huawei.com%2Fnext%2Fgroups%2Findex.html%23%2Fwiki%2Fdetail%3FgroupId%3D2451%26wikiId%3D7801203 | login.huawei.com/login1/?redirect=https%3A%2F%2F3ms.huawei.com%2Fnext%2Fgroups%2Findex.html%23%2Fwiki%2Fdetail%3FgroupId%3D2451%26wikiId%3D7801203
https://login.huawei.com/login1/?redirect=https%3A%2F%2F3ms.huawei.com%2Fkm%2Fblogs%2Fdetails%2F15757169 | login.huawei.com/login1/?redirect=https%3A%2F%2F3ms.huawei.com%2Fkm%2Fblogs%2Fdetails%2F15757169
https://login.huawei.com/login1/?redirect=https%3A%2F%2F3ms.huawei.com%2Fkm%2Fgroups%2F3957217%2Fblogs%2Fdetails%2F15771583 | login.huawei.com/login1/?redirect=https%3A%2F%2F3ms.huawei.com%2Fkm%2Fgroups%2F3957217%2Fblogs%2Fdetails%2F15771583
https://login.huawei.com/login1/?redirect=https%3A%2F%2Fwiki.huawei.com%2Fdomains%2F46331%2Fwiki%2F62321%2FWIKI202309051948105%3Ftitle%3D1--x86%25E6%259C%25BA%25E5%2599%25A8%25E7%25BC%2596%25E8%25AF%2591 | login.huawei.com/login1/?redirect=https%3A%2F%2Fwiki.huawei.com%2Fdomains%2F46331%2Fwiki%2F62321%2FWIKI202309051948105%3Ftitle%3D1--x86%25E6%259C%25BA%25E5%2599%25A8%25E7%25BC%2596%25E8%25AF%2591
https://zhuanlan.zhihu.com/p/706655634 | LLM Self-Improvement 之 概述 - 知乎
https://zhuanlan.zhihu.com/p/1921314417905213679 | 🚀 为什么我选择 A2A：谈谈多智能体系统的未来协作形态 - 知乎
https://zhuanlan.zhihu.com/p/1921914053485376792 | 一文搞懂大模型生成文本的解码策略 - 知乎
https://zhuanlan.zhihu.com/p/1921955715926430072 | 驯服大模型幻觉！抖音用7B小模型+RAG，提升用户满意度 - 知乎
https://zhuanlan.zhihu.com/p/1920155793132621920 | 浅析SOTA向量检索模型(gemini, seed1.5, qwen3)技术细节 - 知乎
https://zhuanlan.zhihu.com/p/1922453251657271046 | 逆向Gemini 2.5 Pro搜索功能 - 知乎
https://zhuanlan.zhihu.com/p/29746278951 | 【阅读笔记】Gemini Embedding：工程>模型 - 知乎
https://github.com/google-gemini/gemini-cli | google-gemini/gemini-cli: An open-source AI agent that brings the power of Gemini directly into your terminal.
https://zhuanlan.zhihu.com/p/49398269658 | SFT-22条经验 - 知乎
https://zhuanlan.zhihu.com/p/1916102534818406913 | 从 Magistral 技术报告看 RL for Reasoning LLM 的最佳实践 - 知乎
https://www.zhihu.com/question/668128319/answer/1919300440677422242 | 研一刚入学导师让我搭各种LLM的Ai Agent框架，应该往什么方向努力才能出成果呢？ - 知乎
https://github.com/stanford-cs336/spring2025-lectures | stanford-cs336/spring2025-lectures
https://www.zhihu.com/question/1910264205526962733/answer/1922427202403824471 | Anthropic 推出的 Claude Code 是什么技术原理呢？ - 知乎
https://github.com/AIDotNet/OpenDeepWiki | AIDotNet/OpenDeepWiki: OpenDeepWiki is the open-source version of the DeepWiki project, aiming to provide a powerful knowledge management and collaboration platform. The project is mainly developed using C# and TypeScript, supporting modular design, and is easy to expand and customize.
https://learn.microsoft.com/en-us/azure/search/retrieval-augmented-generation-overview?tabs=docs | RAG and generative AI - Azure AI Search | Microsoft Learn
https://github.com/wasiahmad/Awesome-LLM-Synthetic-Data | wasiahmad/Awesome-LLM-Synthetic-Data: A reading list on LLM based Synthetic Data Generation 🔥
https://zhuanlan.zhihu.com/p/1923441854436849480 | 都在说压缩即智能，所以大模型到底从数据中压缩了什么？ - 知乎
https://zhuanlan.zhihu.com/p/1923313548446109790 | 斯坦福最新研究重设RAG新基线：你的RAG基准该更新了！2025 - 知乎
https://www.philschmid.de/ | Philschmid
https://www.zhihu.com/question/1914749108511540671/answer/1915977317303433170 | 如何看待Log-linear Attention? - 知乎
https://zhuanlan.zhihu.com/p/680613733 | [文献整理] 大模型对抗攻击 - 知乎
https://github.com/smsquirrel/queryAnnotation | smsquirrel/queryAnnotation
http://114.114.114.114:9421/proxycontrolwarn/httpwarning_3318.html?ori_url=aHR0cHM6Ly93d3cuZGVlcHJhY3RpY2V4LmNvbS9ibG9nL29lcy1mcmFtZXdvcmsuaHRtbA==&uid=0 | HIS Proxy Notification
https://github.com/Deepractice | Deepractice
https://zhuanlan.zhihu.com/p/1924074563257480838 | 蒸馏不需要老师是明星 - 知乎
https://www.zhihu.com/question/1891113677651955809/answer/1917612266716657422 | 为什么开发一个 AI Agent 看似容易，但真正让它「好用」却如此困难？技术瓶颈主要在哪里？ - 知乎
https://www.zhihu.com/question/1914286810902827620/answer/1920233290390016317 | 阿里开源 Qwen3 新模型 Embedding，该模型的框架设计有哪些优势？ - 知乎
https://zhuanlan.zhihu.com/p/1916404037038880288 | 贝叶斯视角下的大模型 - 知乎
https://datasetsearch.research.google.com/search?query=linux&docid=L2cvMTF4N21fY3p4aw%3D%3D | Dataset Search
https://zhuanlan.zhihu.com/p/1925188625085212470 | LLM Agent是否能颠覆传统软件技术架构：反思代码与Prompt的本质差异 2025.7 - 知乎
https://www.zhihu.com/question/1920949805166858531/answer/1925220128485779307 | Anthropic的Claude Code Agent效果很好，有没有人深入分析其技术原理？ - 知乎
https://zhuanlan.zhihu.com/p/1897641358296081771 | 推理模型升级浪潮下，Agentic RAG 如何借力 DeepSeek 实现知识革命？ - 知乎
https://zhuanlan.zhihu.com/p/1925270357792784909 | RAG技术新格局：知识图谱赋能智能检索与生成 - 知乎
https://zhuanlan.zhihu.com/p/1925527434746397144 | Karpathy最新脑洞「细菌编程」：优秀的代码应该具备细菌的三大特质 - 知乎
https://github.com/n8n-io/n8n | n8n-io/n8n: Fair-code workflow automation platform with native AI capabilities. Combine visual building with custom code, self-host or cloud, 400+ integrations.
https://zhuanlan.zhihu.com/p/1925232707593540671 | 给大模型推理加上进度条? - 知乎
https://zhuanlan.zhihu.com/p/24642612039 | 我们相信模型自己是能学会 Sparsity 的 - 知乎
https://zhuanlan.zhihu.com/p/1899069273533581204 | GraphGen:生成海量垂域LLM训练数据 - 知乎
https://www.zhihu.com/question/658814116/answer/1925846145294382244 | 2024年了，kaggle比赛认可度还高吗? - 知乎
https://zhuanlan.zhihu.com/p/1924309705548867391 | 【LLMxRL】熵坍缩与缓解策略 - 知乎
https://github.com/ai-agents-2030/awesome-deep-research-agent | ai-agents-2030/awesome-deep-research-agent
https://zhuanlan.zhihu.com/p/678038828 | 4种约束LLM输出JSON数据的技术方案 - 知乎
https://zhuanlan.zhihu.com/p/709851950 | 大模型预训练（五）：Continued Pre-training for Code or Math Capability - 知乎
https://zhuanlan.zhihu.com/p/809229182 | LLM训练-sft - 知乎
https://www.zhihu.com/column/c_1747590116120698880 | 百面LLM - 知乎
https://zhuanlan.zhihu.com/p/9649266595 | 瞎聊：sft 模型为何不如 pretrain 模型 - 知乎
https://zhuanlan.zhihu.com/p/6497090767 | sft 数据有多少细节？ - 知乎
https://zhuanlan.zhihu.com/p/718354385 | LLM训练-pretrain - 知乎
https://zhuanlan.zhihu.com/p/711537210 | 浅谈领域模型训练 - 知乎
https://zhuanlan.zhihu.com/p/1926535139657253514 | Anthropic 的智能体建造指南：Building Effective AI Agents: A Pragmatic Approach - 知乎
https://zhuanlan.zhihu.com/p/1901810636012368260 | 最顶尖的Prompt都是怎么写的——Cursor篇 - 知乎
https://www.cnblogs.com/whuanle/p/archive/2020/04 | 2020 年 4月 随笔档案 - 痴者工良 - 博客园
https://zhuanlan.zhihu.com/p/1925606546940887339 | 开源Agent新标杆：通义WebSailor多榜夺魁，挑战OpenAI高难度Agent基准BrowseComp - 知乎
https://arxiv.org/pdf/2502.12110 | A-MEM: Agentic Memory for LLM Agents
https://zhuanlan.zhihu.com/p/1927506923424576974 | 【智能体工具学习】Agent-as-Tool: A Study on the Hierarchical Decision Making with Reinforcement Learning - 知乎
http://114.114.114.114:9421/proxycontrolwarn/httpwarning_3318.html?ori_url=aHR0cHM6Ly9hbnlyb3V0ZXIudG9wL2NvbnNvbGU=&uid=0 | HIS Proxy Notification
https://www.zhihu.com/question/1926568965938877727/answer/1927048640993686705 | 频繁刷短视频会让人变浮躁吗？它对我们的专注力和深度思考能力有哪些潜移默化的影响？ - 知乎
https://zhuanlan.zhihu.com/p/1917371436215048041 | 从“结对编程”到“管理AI团队”：我的Async-Agent Coding实践与思考 - 知乎
https://github.com/EasonWong0327/Hybrid-RAG-System/blob/main/QA/data/Chinese-medical-dialogue-data/LICENSE | Hybrid-RAG-System/QA/data/Chinese-medical-dialogue-data/LICENSE at main · EasonWong0327/Hybrid-RAG-System
https://zhuanlan.zhihu.com/p/1927740021550606048 | COT (链式推理) 数据提取方法综述 - 知乎
https://zhuanlan.zhihu.com/p/1918466337782604681 | 别玩Native RAG了，试试手搓一个DeepSearch - 知乎
https://github.com/Paul33333/Agentic_RAG | Paul33333/Agentic_RAG: Local DeepSearch (Advantage: Low Threshold): an implementation of Agentic RAG based on DeepSeek-R1 API and Tavily API
https://zhuanlan.zhihu.com/p/1888964056448233510 | zilvus的deepsearcher源码解读之后的原理 - 知乎
https://zhuanlan.zhihu.com/p/1926055354426458199 | 深度研究智能体（Deep Research Agent）全面综述：从技术架构到未来挑战 - 知乎
https://github.com/aneasystone/weekly-practice | aneasystone/weekly-practice: 日拱一卒，功不唐捐。
https://github.com/SWE-agent/SWE-agent | SWE-agent/SWE-agent: SWE-agent takes a GitHub issue and tries to automatically fix it, using your LM of choice. It can also be employed for offensive cybersecurity or competitive coding challenges. [NeurIPS 2024]
https://zhuanlan.zhihu.com/p/28564341033 | RooCode (Cline) Agent 框架分析 - 知乎
https://github.com/HKUDS/Auto-Deep-Research | HKUDS/Auto-Deep-Research: "Your Fully-Automated Personal AI Assistant"
https://github.com/zilliztech/deep-searcher | zilliztech/deep-searcher: Open Source Deep Research Alternative to Reason and Search on Private Data. Written in Python.
https://github.com/davidkimai/Context-Engineering | davidkimai/Context-Engineering: "Context engineering is the delicate art and science of filling the context window with just the right information for the next step." — Andrej Karpathy. A frontier, first-principles handbook inspired by Karpathy and 3Blue1Brown for moving beyond prompt engineering to the wider discipline of context design, orchestration, and optimization.
https://github.com/AsyncFuncAI/deepwiki-open | AsyncFuncAI/deepwiki-open: Open Source DeepWiki: AI-Powered Wiki Generator for GitHub/Gitlab/Bitbucket Repositories. Join the discord: https://discord.gg/gMwThUMeme
https://github.com/ngl567/KGR-Survey | ngl567/KGR-Survey: A Survey of Task-Oriented Knowledge Graph Reasoning: Status, Applications, and Prospects
https://zhuanlan.zhihu.com/p/1929173673274769881 | TRAE Agent 在 SWE-bench Verified 上得分 75.2%，并已开源 - 知乎
https://zhuanlan.zhihu.com/p/26560000573 | DeepSearch 与 DeepResearch 的设计和实现 - 知乎
https://zhuanlan.zhihu.com/p/20462236939 | 【论文解读】Condor：合成高质量SFT数据的两阶段框架 - 知乎
https://zhuanlan.zhihu.com/p/1923006942365852721 | 为什么解码原理是深入理解大模型的关键起点 - 知乎
https://zhuanlan.zhihu.com/p/1930731262445877058 | 为什么语义无法被计算？｜Why Can't Semantics Be Computed? - 知乎
https://www.moderne.ai/blog/introducing-moderne-multi-repo-ai-agent-for-transforming-code-at-scale | New Multi-repo AI Agent | Moderne
https://arxiv.org/pdf/2502.12929 | Flow-of-Options: Diversified and Improved LLM Reasoning by Thinking Through Options
http://114.114.114.114:9421/proxycontrolwarn/httpwarning_3318.html?ori_url=aHR0cHM6Ly9kZXZlbG9wZXJzLmxsYW1haW5kZXguYWkvcHl0aG9uL2ZyYW1ld29yay91bmRlcnN0YW5kaW5nL2FnZW50L211bHRpX2FnZW50Lw==&uid=0#pattern-2--orchestrator-agent-sub-agents-as-tools | HIS Proxy Notification
http://114.114.114.114:9421/proxycontrolwarn/httpwarning_3318.html?ori_url=aHR0cHM6Ly9kZXZlbG9wZXJzLmxsYW1haW5kZXguYWkvcHl0aG9uL2V4YW1wbGVzL2FnZW50L211bHRpX2RvY3VtZW50X2FnZW50cy12MS8=&uid=0 | HIS Proxy Notification
https://zhuanlan.zhihu.com/p/1931026753767338132 | Kiro Spec工作流从理念到实践 - 在Cursor与Claude Code中构建系统化AI开发流程 - 知乎
https://www.zhihu.com/question/14341004439/answer/1904077596196599306 | Manus会不会开源？ - 知乎
https://zhuanlan.zhihu.com/p/1902504078115861988 | Roo-Code\Cline 源码分析 -7- 完整流程 - 知乎
https://zhuanlan.zhihu.com/p/1930154426397602758 | Cline Memory Bank: 自主构建和维护文档系统实现项目持久记忆 - 知乎
https://zhuanlan.zhihu.com/p/1914230995034564014 | Agent/LangGraph 面试八股文：核心难题20题 - 知乎
https://www.zhihu.com/question/5374267242 | 如何选择最适合构建多智能体AI应用的框架？ - 知乎
https://www.graphlit.com/blog/survey-of-ai-agent-memory-frameworks | Survey of AI Agent Memory Frameworks - Graphlit
https://github.com/nuster1128/LLM_Agent_Memory_Survey | nuster1128/LLM_Agent_Memory_Survey
https://zhuanlan.zhihu.com/p/1931855648657737391 | 金融通用智能体底层架构深度解析白皮书 - 知乎
https://zhuanlan.zhihu.com/p/1929913920522551983 | Claude Code Agent分析三：控制流与编排引擎 - 知乎
https://github.com/humanlayer/12-factor-agents/tree/main | humanlayer/12-factor-agents: What are the principles we can use to build LLM-powered software that is actually good enough to put in the hands of production customers?
https://www.llamaindex.ai/blog/improved-long-and-short-term-memory-for-llamaindex-agents | Improved Long & Short-Term Memory for LlamaIndex Agents — LlamaIndex - Build Knowledge Assistants over your Enterprise Data
https://open.codehub.huawei.com/innersource/APN4AI4net_G/APN4AI4net/files?ref=master&filePath=PADSagent%2FDiagEngine.py&isFile=true | CodeHub
https://open.codehub.huawei.com/innersource/Agentless_G/agentless_sft/files?ref=master | CodeHub
https://open.codehub.huawei.com/innersource/SWE-Agent_G/CodFix/CodeFixAgent/files?ref=master&filePath=src%2Fprompts%2Fplanner_model.py&isFile=true | CodeHub
https://open.codehub.huawei.com/innersource/SWEG/CodeAnchor/tree-sitter-cli/files?ref=master | CodeHub
https://github.com/bytedance/trae-agent | bytedance/trae-agent: Trae Agent is an LLM-based agent for general purpose software engineering tasks.
https://zhuanlan.zhihu.com/p/1932900716554486132 | 100行代码打造迷你编程Agent：修复65%真项目bug，适配所有大模型 - 知乎
https://jx.huawei.com/community/ | 稼先社区
https://jx.huawei.com/community/comgroup/postsDetails?postId=3ea3376c92f64537b31d732b323b24a0&noTop=true&type=freePost&welink_open_uri=aDU6Ly80NzE2NTE3MzE0Nzc5NTcvaHRtbC9pbmRleC5odG1sIy9qeC9kZXRhaWw%2FaWQ9M2VhMzM3NmM5MmY2NDUzN2IzMWQ3MzJiMzIzYjI0YTAmdHlwZT1mcmVlX3Bvc3QmdXJsPQ%3D%3D | 稼先社区
https://zhuanlan.zhihu.com/p/1933175160711672841 | 100行代码打造编程Agent：能修复65%真实项目bug，适配所有大模型 - 知乎
https://www.zhihu.com/search?type=content&q=ICL%20%E8%B0%B7%E6%AD%8C | ICL 谷歌 - 搜索结果 - 知乎
https://zhuanlan.zhihu.com/p/1935904538470114067 | Graphiti-构建适用于 AI 智能体的实时知识图谱 - 知乎
https://jx.huawei.com/community/comgroup/postsDetails?postId=03c4aea9a7d44f0fbacaa149e03ca89b&noTop=true&type=freePost&welink_open_uri=aDU6Ly80NzE2NTE3MzE0Nzc5NTcvaHRtbC9pbmRleC5odG1sIy9qeC9kZXRhaWw%2FaWQ9MDNjNGFlYTlhN2Q0NGYwZmJhY2FhMTQ5ZTAzY2E4OWImdHlwZT1mcmVlX3Bvc3QmdXJsPQ%3D%3D | 稼先社区
https://jx.huawei.com/community/comgroup/postsDetails?postId=93c3f94eae14454ba4ed55ddcb3daad3&noTop=true&type=freePost&welink_open_uri=aDU6Ly80NzE2NTE3MzE0Nzc5NTcvaHRtbC9pbmRleC5odG1sIy9qeC9kZXRhaWw%2FaWQ9OTNjM2Y5NGVhZTE0NDU0YmE0ZWQ1NWRkY2IzZGFhZDMmdHlwZT1mcmVlX3Bvc3QmdXJsPQ%3D%3D | 稼先社区
https://jx.huawei.com/community/comgroup/postsDetails?postId=096a247e906a4315bec671d0db65d6db&welink_open_uri=aDU6Ly80NzE2NTE3MzE0Nzc5NTcvaHRtbC9pbmRleC5odG1sIy9qeC9kZXRhaWw%2FaWQ9MDk2YTI0N2U5MDZhNDMxNWJlYzY3MWQwZGI2NWQ2ZGImdHlwZT1mcmVlX3Bvc3QmdXJsPQ%3D%3D | 稼先社区
https://jx.huawei.com/community/comgroup/postsDetails?postId=b605379ed4944184ad81f06030dce675&noTop=true&type=freePost&welink_open_uri=aDU6Ly80NzE2NTE3MzE0Nzc5NTcvaHRtbC9pbmRleC5odG1sIy9qeC9kZXRhaWw%2FaWQ9YjYwNTM3OWVkNDk0NDE4NGFkODFmMDYwMzBkY2U2NzUmdHlwZT1mcmVlX3Bvc3QmdXJsPQ%3D%3D | 稼先社区
https://login.huawei.com/login1/?redirect=https%3A%2F%2F3ms.huawei.com%2Fkm%2Fblogs%2Fdetails%2F21494043%3Fl%3Dzh-cn | login.huawei.com/login1/?redirect=https%3A%2F%2F3ms.huawei.com%2Fkm%2Fblogs%2Fdetails%2F21494043%3Fl%3Dzh-cn
https://zhuanlan.zhihu.com/p/1932537258289893532 | Google ADK源码初探: Agent 如何与LLM协同工作 - 知乎
https://microsoft.github.io/autogen/0.2/docs/Examples/ | Examples | AutoGen 0.2
https://zhuanlan.zhihu.com/p/1927402577835852203 | 名词→动词→引擎→点火钥匙：适合 Agent 的多文件软件工程开发方法 - 知乎
https://jx.huawei.com/community/comgroup/postsDetails?postId=a94d50a0dc99471b8b0c56a101e427fd&noTop=true&type=freePost&welink_open_uri=aDU6Ly80NzE2NTE3MzE0Nzc5NTcvaHRtbC9pbmRleC5odG1sIy9qeC9kZXRhaWw%2FaWQ9YTk0ZDUwYTBkYzk5NDcxYjhiMGM1NmExMDFlNDI3ZmQmdHlwZT1mcmVlX3Bvc3QmdXJsPQ%3D%3D | 稼先社区
https://github.com/bmad-code-org/BMAD-METHOD | bmad-code-org/BMAD-METHOD: Breakthrough Method for Agile Ai Driven Development
https://zhuanlan.zhihu.com/p/1940824548485347192 | OpenHands 源码解读 - 知乎
https://zhuanlan.zhihu.com/p/1940857616717837697 | 读论文：几个小技巧搞砸你的万亿 token 合成语料库 - 知乎
http://114.114.114.114:9421/proxycontrolwarn/httpwarning_3318.html?ori_url=aHR0cHM6Ly9kZXZlbG9wZXJzLmxsYW1haW5kZXguYWkvcHl0aG9uL2ZyYW1ld29yay1hcGktcmVmZXJlbmNlL2FnZW50Lw==&uid=0#llama_index.core.agent.workflow.BaseWorkflowAgent.setup_agent | HIS Proxy Notification
https://zhuanlan.zhihu.com/p/1936459483481110052 | 文本扩散模型：dreamOn - 知乎
https://zhuanlan.zhihu.com/p/1919543400140605201 | AI时代软件工程实践心得与不完全指北(part 5: Ch. 7~8) - 知乎
https://zhuanlan.zhihu.com/p/1940846596980998260 | M3-Agent：为 AI 智能体构建「长期记忆」 - 知乎
https://developers.llamaindex.ai/python/framework/understanding/agent/multi_agent/ | Multi-agent patterns in LlamaIndex | LlamaIndex Python Documentation
https://zhuanlan.zhihu.com/p/1943451926181164200 | cognee：当前效果最好的AI Agent记忆层(vs LightRAG/Mem0/Graphiti) - 知乎
https://zhuanlan.zhihu.com/p/1927006780812170879 | 一文读懂LLM后训练的原理与实操 - 知乎
https://github.com/LingmaTongyi/Lingma-SWE-GPT/blob/main/app/MCTS/mtcs_repo_graph.py | Lingma-SWE-GPT/app/MCTS/mtcs_repo_graph.py at main · LingmaTongyi/Lingma-SWE-GPT
https://login.huawei.com/login1/?redirect=https%3A%2F%2Fwiki.huawei.com%2Fdomains%2F88471%2Fwiki%2F197009%2FWIKI202507177542312 | login.huawei.com/login1/?redirect=https%3A%2F%2Fwiki.huawei.com%2Fdomains%2F88471%2Fwiki%2F197009%2FWIKI202507177542312
https://jx.huawei.com/community/comgroup/postsDetails?postId=336b9a616e5d4d58bfe0a6ad3d39eb38&noTop=true&type=freePost&welink_open_uri=aDU6Ly80NzE2NTE3MzE0Nzc5NTcvaHRtbC9pbmRleC5odG1sIy9qeC9kZXRhaWw%2FaWQ9MzM2YjlhNjE2ZTVkNGQ1OGJmZTBhNmFkM2QzOWViMzgmdHlwZT1mcmVlX3Bvc3QmdXJsPQ%3D%3D | 稼先社区
https://jx.huawei.com/community/comgroup/postsDetails?postId=fcdc9fa80b91492da8d54193d50dab6e&noTop=true&type=freePost&zoneId=11&target=zone_all&welink_open_uri=aDU6Ly80NzE2NTE3MzE0Nzc5NTcvaHRtbC9pbmRleC5odG1sIy9qeC9kZXRhaWw%2FaWQ9ZmNkYzlmYTgwYjkxNDkyZGE4ZDU0MTkzZDUwZGFiNmUmdHlwZT1mcmVlX3Bvc3QmdXJsPQ%3D%3D | 稼先社区
https://www.zhihu.com/question/333196499/answer/1949096106429505832 | 知识蒸馏knowledge distillation 在自然语言处理NLP中有哪些方面的应用或发展？ - 知乎
https://zhuanlan.zhihu.com/p/25725723409 | test-time scaling个人理解与总结 - 知乎
https://zhuanlan.zhihu.com/p/1950861524764722855 | 我使用Autogen GraphFlow和Qwen3 Coder求解数学难题，还成功了 - 知乎
https://login.huawei.com/login1/?redirect=https%3A%2F%2Filearning.huawei.com%2Fedx%2Fnext%2Fprogram%2F583679230513909760 | login.huawei.com/login1/?redirect=https%3A%2F%2Filearning.huawei.com%2Fedx%2Fnext%2Fprogram%2F583679230513909760
https://login.huawei.com/login1/?redirect=https%3A%2F%2F3ms.huawei.com%2Fhi%2Fgroup%2F3543393 | login.huawei.com/login1/?redirect=https%3A%2F%2F3ms.huawei.com%2Fhi%2Fgroup%2F3543393
https://login.huawei.com/login1/?redirect=https%3A%2F%2F3ms.huawei.com%2Fdocuments%2Fdocinfo%2F1167548736705740800%3FattachmentIdx%3D0%26attachmentPage%3D30 | login.huawei.com/login1/?redirect=https%3A%2F%2F3ms.huawei.com%2Fdocuments%2Fdocinfo%2F1167548736705740800%3FattachmentIdx%3D0%26attachmentPage%3D30
https://login.huawei.com/login1/?redirect=https%3A%2F%2Filearning.huawei.com%2Fcourse%2F100000%2Fapplication-learn%2FCOU20250826000003%3FclassCode%3D%26sourcesType%3D%26blockType%3D%26blockId%3D%26sxz-lang%3Dzh_CN%23bf9f6e662bf24bcebf8d8f47e25f04ba | login.huawei.com/login1/?redirect=https%3A%2F%2Filearning.huawei.com%2Fcourse%2F100000%2Fapplication-learn%2FCOU20250826000003%3FclassCode%3D%26sourcesType%3D%26blockType%3D%26blockId%3D%26sxz-lang%3Dzh_CN%23bf9f6e662bf24bcebf8d8f47e25f04ba
https://zhuanlan.zhihu.com/p/1953262318352863784 | 通义实验室DeepResearch系列论文解读 - 知乎
https://www.zhihu.com/question/1923049104222721873/answer/1953934765909583735 | 为什么感觉现在AI Agent都是雷声大雨点小？ - 知乎
https://zhuanlan.zhihu.com/p/1952343182063936280 | 杂谈 MoE，FFN，Attention，统一。UMoE （Neurips 25 spotlight） - 知乎
https://zhuanlan.zhihu.com/p/919311018 | [133] CoRe: Verifier+MCTS+迭代 提升LLM(数学)推理能力 - 知乎
https://zhuanlan.zhihu.com/p/1954613742634504507 | 美团 LongCat-Flash-Thinking 技术报告 - 知乎
https://zhuanlan.zhihu.com/p/1956092711749808495 | 从零构建能自我优化的AI Agent：Reflection和Reflexion机制对比详解与实现 - 知乎
https://zhuanlan.zhihu.com/p/1956110736427286652 | Trae-Agent 核心执行思路深度解析 - 知乎
https://zhuanlan.zhihu.com/p/1956009286288259057 | 【RAG-答案生成】WeStar微信统一风格客服回答 - 知乎
