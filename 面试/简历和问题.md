

Linux驱动代码的鸿蒙切换






# 关于微调



## UCL代码编写能力的微调

第一版的做法是 从 




# 关于Agent

## 1. 业务代码能力和算法竞赛代码能力的差异点在哪，AI能否解决，AI解决的方式将会是不同的，

## 2. agent 和 workflow的能力差异点 ，



## 3. 上线agent 重要的是什么




## 4. 如何避免沦为 prompt 调优


使用结构化的输出，明确输出的几个字段属性，通过不断的加减prompt的调优


## 5. 长流程的agent 的执行能力的确保

- 使用预先定义的中间结果字段



## 6. 如何保证agent的结果可靠性

核心是大量的中间结果的可靠 验证，而不能交付给 最终的验证机器




## 7. 构建agent应用的关键 核心是什么

大量的时间应该花在
-  理解任务需求 理解任务的可能的中间步骤 输入输出等 
-  构建大量的应用执行的相关的tools
-  构建可视化 可观测性的 agent 执行平台，尤其是对中间结果的记录，包括tool 调用
-  如果可以，构建评测数据



调优应该在

- 理解llm做出的tool选择 和输出内容 ，当与预期不一致时，尝试理解llm的选择
- 调优 tool， 
- 构建任务的长期记忆机制，在大规模应用的时候，长期记忆可以帮助解决相似类型输入



## 当前agent的问题是什么

1. 无法实现连续的多轮调用工具，这一点无法稳定实现，即使只是简单的调用关系（例如查找符号位置，然后打开所在文件，然后进行判断，然后重复上述过程） 


## 8. 多agent的应用 该如何设计，缺陷是什么，有哪些应用场景，





## 9. 未来agent的发展方向 或者说 一个优秀的 agent 应用应该具有哪些特征


- 1. 一个llm可视的 文件系统 ，可以用于llm进行记录 任务状态 中间结果 等等 ，当任务结束后，会将其总结 写入 长期记忆的磁盘中去

- 2. 优秀的 长短期 记忆模块设计，

- 2. 优秀的可观测性，任务失败的定位机制

- 3. 便捷的 步骤插入和中间预期输入的 插入机制



- 4. 优秀的全局状态 局部步骤状态 的记录 系统 



参考claude 和 devin公司的博客，例如
    [理解Claude Code的Agent设计理念(上）](https://zhuanlan.zhihu.com/p/1951279182551188824)


## 10. 单agent 和 多agent 系统的差异，  哪种更好 


pass



## 为什么agent的实际效果总是不好

1。 在实际的任务过程中，例如 公司的项目环境上的llm 编码， 和算法竞赛题的编码任务，二者不同的点在于， 在实际的项目中，llm 面对的一定是一个信息不足的状态，但是算法竞赛 的题目描述，所需要的编程库 一定都是信息充分的情况下，这不是一个模糊的需求，也不需要复杂的库

1. 领域数据匮乏 ，大量的公司的存量代码库，自行封装的接口库，


依赖复杂的提示和设计，才能完成，需要合成数据

2. llm的工作区 存在大量的函数调用是未知的， 各种接口，他们不是训练过后的库 ，上下文窗口是有限的

1. llm 非常容易被工具输出冲昏头脑， 失去全局目标


2. llm会朝着最小成本解决目标的方向前进，而训练时候rl设置 类似agent的门禁机制，会极大影响llm ， 例如为了使得编译通过，干脆直接伪造一堆没生成实现的函数声明（ucl生成中）只是为了编译通过， 在gemini中非常喜欢各种防御性编程，例如导入模块，例如明明给出的我的文件已经导入了某个方法，他还是自己实现了一个mock版，只是为了防止编译不通过 



3. 在代码领域，llm的训练都



## agent rl怎样才能做好

1. 设计多个工具调用，即对一个中间目标达成，可能有多个路径可以达到，即多个工具调用链，例如查看代码调用片段， get_c_tag , 或者 直接search_code , open_file(带有行号)等

当有open file的时候，自动调用 note工具，记录下查看文件的结果，自己维护自己的短期记忆和长期记忆**不断的维护自己的history messages 和 长期记忆 记录下调用工具得到的各种信息，按照标签记录下来**


2 ,一个优秀的agent的应该可以自己记录自己的上下文，即自己管理自己的上下文**和人类似的是，人也是管理llm的上下文 ，做一个精细的管理**


## 如何提升code agent的质量 ，在你自己使用code agent辅助编码时候有哪些技巧


code is cheap , design is important 


llm本质上是拟合，并不具备真正的推理能力，

变量替换法，如果把一个程序的变量进行替换,替换为歧义名，llm很可能就做不出来了


- 命名的高度可读性，相关性
- 提前完成基础的框架搭建，即定义好函数，变量，搭建好骨架，让llm做确定的事，减少发散空间，一个函数的输入和输出被定义好，功能由准确的命名和相关的其他函数
- 尤其关注重要函数，提前定义好，即帮助llm完成step by step的预先定义






# 关于RAG


## RAG的问题

## open deepwiki 



# 关于鸿蒙切换

## 1. 任务的难点

