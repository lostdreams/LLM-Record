

Linux驱动代码的鸿蒙切换





















# 简历问题


## ucl 流程

任务输入 ->  check linux 代码 -> 





## ucl指标

- 行占比
- bleu , 
- n gram , 
- udk_symbol_ngram
- llm_evaluate
- 

## 代码切换任务难点

- 一些基础的组件功能具有对应关系，但是更多的驱动框架相关的无映射关系， 其数据结构就天然不同 ，但是简单的对应又希望不用AI做

- 对于ucl来说， 执行链路长，涉及代码仓多，尤其是鸿蒙 内核api代码仓庞大，
- ucl是在内核代码仓上添加接口，

- 通用问题： 不了解鸿蒙有哪些接口，就算给了接口，他也不太会用，因为难以理解底层机制和实现



-  难以评测，目前还在 建立 从生成 到 生成测试用例，构建qemu 环境运行测试用例 
-  实现



## 遇到问题

- 知识匮乏下的，幻觉问题，
- 奖励劫持，因为有编译这道门禁，干脆虚拟接口，但不给出实现，只要编译能过
- 实现复杂的multi agent 调用


- 对于检索问题： 目前做法是 api检索 ，llm补齐api信息描述， 使用文本到文本检索， 


- 对于缺少理解怎么使用的问题: react 阅读文件 【 静态分析抽取符号依赖关系，构图】


- 规模化应用的 : 并发性，工具稳定性，问题的可观测性（复杂链路下问题定位）

## 尝试做法

- 微调提升llm 模型推理能力，写ucl,---》 使用ds r1 合成推理数据链， 
- 继续预训练 ，--》 数据量少，知识冲突， 20w条， 合成说明  --> 过拟合

- 解决api信息缺少问题  --> 


## 接下来做法
 
- 合成数据这一块，借助目前的workflow,将全链路流程 合并起来做一个推理链， 增强llm能力，主要是回溯能力，主动check能力

- 继续预训练，精细化数据，抽取以前linux问题 合SFT 


- 检索： 
   文件, control， 

- 使用autogen graph功能重构完整流程

- 构建完整的检测 记录 前端和后端，




## 任务背景


三个层面

- 驱动模块补齐，大的repo级的
- API接口适配： os侧  -- 
- API接口适配： 应用侧 -- 广泛匹配

## 



# 关于微调



## UCL代码编写能力的微调

第一版的做法是 从 




# 关于Agent

## 1. 业务代码能力和算法竞赛代码能力的差异点在哪，AI能否解决，AI解决的方式将会是不同的，

## 2. agent 和 workflow的能力差异点 ，



## 3. 上线agent 重要的是什么

- 可靠性
- 可观测性
- 


## 4. 如何避免沦为 prompt 调优


使用结构化的输出，明确输出的几个字段属性，通过不断的加减prompt的调优


## 5. 长流程的agent 的执行能力的确保

- 使用预先定义的中间结果字段



## 6. 如何保证agent的结果可靠性

核心是大量的中间结果的可靠 验证，而不能交付给 最终的验证机器




## 7. 构建agent应用的关键 核心是什么

大量的时间应该花在
-  理解任务需求 理解任务的可能的中间步骤 输入输出等 
-  构建大量的应用执行的相关的tools
-  构建可视化 可观测性的 agent 执行平台，尤其是对中间结果的记录，包括tool 调用
-  如果可以，构建评测数据



调优应该在

- 理解llm做出的tool选择 和输出内容 ，当与预期不一致时，尝试理解llm的选择
- 调优 tool， 
- 构建任务的长期记忆机制，在大规模应用的时候，长期记忆可以帮助解决相似类型输入



## 当前agent的问题是什么

1. 无法实现连续的多轮调用工具，这一点无法稳定实现，即使只是简单的调用关系（例如查找符号位置，然后打开所在文件，然后进行判断，然后重复上述过程） 


## 8. 多agent的应用 该如何设计，缺陷是什么，有哪些应用场景，





## 9. 未来agent的发展方向 或者说 一个优秀的 agent 应用应该具有哪些特征


- 1. 一个llm可视的 文件系统 ，可以用于llm进行记录 任务状态 中间结果 等等 ，当任务结束后，会将其总结 写入 长期记忆的磁盘中去

- 2. 优秀的 长短期 记忆模块设计，

- 2. 优秀的可观测性，任务失败的定位机制

- 3. 便捷的 步骤插入和中间预期输入的 插入机制



- 4. 优秀的全局状态 局部步骤状态 的记录 系统 



参考claude 和 devin公司的博客，例如
    [理解Claude Code的Agent设计理念(上）](https://zhuanlan.zhihu.com/p/1951279182551188824)


## 10. 单agent 和 多agent 系统的差异，  哪种更好 


pass



## 为什么agent的实际效果总是不好

1。 在实际的任务过程中，例如 公司的项目环境上的llm 编码， 和算法竞赛题的编码任务，二者不同的点在于， 在实际的项目中，llm 面对的一定是一个信息不足的状态，但是算法竞赛 的题目描述，所需要的编程库 一定都是信息充分的情况下，这不是一个模糊的需求，也不需要复杂的库

1. 领域数据匮乏 ，大量的公司的存量代码库，自行封装的接口库，


依赖复杂的提示和设计，才能完成，需要合成数据

2. llm的工作区 存在大量的函数调用是未知的， 各种接口，他们不是训练过后的库 ，上下文窗口是有限的

1. llm 非常容易被工具输出冲昏头脑， 失去全局目标


2. llm会朝着最小成本解决目标的方向前进，而训练时候rl设置 类似agent的门禁机制，会极大影响llm ， 例如为了使得编译通过，干脆直接伪造一堆没生成实现的函数声明（ucl生成中）只是为了编译通过， 在gemini中非常喜欢各种防御性编程，例如导入模块，例如明明给出的我的文件已经导入了某个方法，他还是自己实现了一个mock版，只是为了防止编译不通过 



3. 在代码领域，llm的训练都



## agent rl怎样才能做好

1. 设计多个工具调用，即对一个中间目标达成，可能有多个路径可以达到，即多个工具调用链，例如查看代码调用片段， get_c_tag , 或者 直接search_code , open_file(带有行号)等

当有open file的时候，自动调用 note工具，记录下查看文件的结果，自己维护自己的短期记忆和长期记忆**不断的维护自己的history messages 和 长期记忆 记录下调用工具得到的各种信息，按照标签记录下来**


2 ,一个优秀的agent的应该可以自己记录自己的上下文，即自己管理自己的上下文**和人类似的是，人也是管理llm的上下文 ，做一个精细的管理**


## 如何提升code agent的质量 ，在你自己使用code agent辅助编码时候有哪些技巧


code is cheap , design is important 


llm本质上是拟合，并不具备真正的推理能力，

变量替换法，如果把一个程序的变量进行替换,替换为歧义名，llm很可能就做不出来了


- 命名的高度可读性，相关性
- 提前完成基础的框架搭建，即定义好函数，变量，搭建好骨架，让llm做确定的事，减少发散空间，一个函数的输入和输出被定义好，功能由准确的命名和相关的其他函数
- 尤其关注重要函数，提前定义好，即帮助llm完成step by step的预先定义






# 关于RAG


## RAG的问题

## open deepwiki 



# 关于鸿蒙切换

## 1. 任务的难点

